---
title: K methode
comments: true
mathjax: true
date: 2018-11-21 23:26:30
long:
tags:
categories: python
---
### 概述
k 近邻算法采用测量不同特征值之间的距离方法进行分类。
优点：精度高，对异常值不敏感，无数据输入假定。
缺点：计算复杂度高，空间复杂度高。
适用数据范围：数值型和标称型。
### 原理
存在一个样本数据集合，每个数据有自己的标签。当我们输入新的数据后，会计算新数据的每个特征与样本集中数据对应的特征进行比较，然后算法提取样本集中特征最相似数据的分类标签。一般来说我们只选择样本数据集中前k个最相似的数据。
例：电影分类，分开爱情片和动作片。
输入一个未知电影，计算未知电影与爱情片和动作片的距离。
### 流程
1.收集数据，使用任何方法。
2.准备数据，距离计算所需要的数值，最好是结构化的数据格式。
4.训练算法，此步骤不适合k-近邻算法。
5.测试算法，计算错误率。
6.使用算法，首先需要输入样本数据和结构化的输出结果，然后运行k-近邻算法判定输入数据分别属于哪个分类，最后应用对计算出的分类执行后续的处理。
### 准备
首先，创建名为knn.py的python模块。
{% codeblock %}
from numpy import *
def createDataSet():
    group = array([[1.0,1.1],[1.0,1.0],[0,0]])
    labels = ['A','A','B','B']
    return group,labels


{% endcodeblock %}
然后我们调用我的新建的knn模块。
{% codeblock %}
import knn
group,labels = knn.createDataSet()
{% endcodeblock %}

### 实施knn算法
1.计算已知类别属性的数据集中的每个点与当前点的距离
2.按照距离递增次序排序
3.先取与当前点距离最小的k个点
4.确定前k个点所在类别出现频率
5.返回前k个点出现频率最高的类别作为当前点的预测分类

